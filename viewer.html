<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Scope Viewer</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { background: #000; width: 100vw; height: 100vh; overflow: hidden; }
    video { width: 100%; height: 100%; object-fit: contain; display: block; }
    #status {
      position: fixed; bottom: 10px; right: 12px;
      font-family: monospace; font-size: 11px; color: #444;
      pointer-events: none;
    }
    #info {
      position: fixed; bottom: 10px; left: 12px;
      font-family: monospace; font-size: 11px; color: #444;
      pointer-events: none;
    }
    #webcam-ctrl {
      position: fixed; top: 10px; right: 12px;
      font-family: monospace; font-size: 10px;
      background: transparent; border: 1px solid #2a2a2a; color: #2a2a2a;
      padding: 3px 8px; border-radius: 3px; cursor: pointer;
      width: auto; transition: color 0.2s, border-color 0.2s;
    }
    #webcam-ctrl:hover { border-color: #555; color: #555; }
    #webcam-ctrl.active { border-color: #00ff88; color: #00ff88; }
    #webcam-ctrl.error { border-color: #ff4444; color: #ff4444; }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <button id="webcam-ctrl" title="Toggle webcam as pipeline video input">CAM</button>
  <div id="status">connecting...</div>
  <div id="info"></div>

  <script>
    // Read ?scope= param — if present, tell the bridge server which Scope to proxy to.
    // In TouchDesigner Web Render TOP, set URL to:
    //   http://localhost:8080/viewer                          (local)
    //   https://abc-8080.proxy.runpod.net/viewer?scope=abc-8000.proxy.runpod.net  (RunPod)
    const scopeParam = new URLSearchParams(location.search).get("scope");
    const API_BASE = "";

    const videoEl    = document.getElementById("video");
    const statusEl   = document.getElementById("status");
    const infoEl     = document.getElementById("info");
    const webcamCtrl = document.getElementById("webcam-ctrl");

    function connectionLabel() {
      if (!scopeParam) return "local";
      if (scopeParam.includes(".proxy.runpod.net")) {
        const podPart = scopeParam.split(".proxy.runpod.net")[0];
        const podId = podPart.substring(0, podPart.lastIndexOf("-"));
        return `runpod · ${podId}`;
      }
      return scopeParam;
    }

    let dataChannel = null;
    let pendingParams = {};
    let sendTimer = null;
    let lastKnownParams = {};

    // _startGen is incremented every time start() is called.
    // Each invocation captures its own gen value. Whenever gen !== _startGen,
    // the call has been superseded (e.g. by a webcam toggle) and must abort.
    let _startGen = 0;
    let _activePc = null;

    // Webcam stream — if non-null its video track is added to the WebRTC offer
    let _webcamStream = null;

    let _frameCount = 0, _fpsTime = performance.now();
    function startFPS() {
      if (!videoEl.requestVideoFrameCallback) return;
      const label = connectionLabel();
      function onFrame() {
        _frameCount++;
        const now = performance.now();
        if (now - _fpsTime >= 1000) {
          const fps = (_frameCount / ((now - _fpsTime) / 1000)).toFixed(1);
          infoEl.textContent = `${label} · ${fps} fps`;
          _frameCount = 0;
          _fpsTime = now;
        }
        videoEl.requestVideoFrameCallback(onFrame);
      }
      videoEl.requestVideoFrameCallback(onFrame);
    }

    function scheduleSend() {
      if (sendTimer) return;
      sendTimer = setTimeout(() => {
        sendTimer = null;
        if (dataChannel && dataChannel.readyState === "open" && Object.keys(pendingParams).length) {
          dataChannel.send(JSON.stringify(pendingParams));
          pendingParams = {};
        }
      }, 16);
    }

    function connectWebSocket() {
      const wsProto = location.protocol === "https:" ? "wss" : "ws";
      const ws = new WebSocket(`${wsProto}://${location.host}/ws`);

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        if (data._mapped === false) return;
        const params = {};
        Object.entries(data)
          .filter(([k]) => !k.startsWith("_"))
          .forEach(([k, v]) => { params[k] = v; });
        if (params.pipeline_ids) {
          lastKnownParams = params;
        } else {
          Object.assign(lastKnownParams, params);
        }
        Object.assign(pendingParams, params);
        scheduleSend();
      };

      ws.onclose = () => setTimeout(connectWebSocket, 2000);
    }

    connectWebSocket();

    // Connect to Scope and start streaming.
    // Uses a generation counter (_startGen) so that when this is called again
    // (e.g. webcam toggled), the previous invocation self-aborts at the next
    // await rather than racing to create a second peer connection.
    async function start() {
      const gen = ++_startGen;

      try {
        if (scopeParam) {
          await fetch("/config/scope", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ host: scopeParam })
          }).catch(() => {});
        }
        if (gen !== _startGen) return;

        statusEl.textContent = "waiting for pipeline...";
        while (true) {
          if (gen !== _startGen) return; // superseded — bail out
          try {
            const r = await fetch(`${API_BASE}/api/v1/pipeline/status`, { cache: "no-store" });
            if (r.ok) {
              const { status } = await r.json();
              if (status === "loaded") break;
              if (status === "error") statusEl.textContent = "pipeline error";
            }
          } catch (_) {}
          await new Promise(r => setTimeout(r, 2000));
        }
        if (gen !== _startGen) return;

        statusEl.textContent = "connecting WebRTC...";

        const iceRes = await fetch(`${API_BASE}/api/v1/webrtc/ice-servers`, { cache: "no-store" });
        const { iceServers } = await iceRes.json();
        if (gen !== _startGen) return;

        const pc = new RTCPeerConnection({ iceServers });
        _activePc = pc;

        // If webcam is active, send its video track to Scope as pipeline video input.
        // Must happen before createOffer() so the send transceiver appears in the SDP.
        if (_webcamStream) {
          const videoTrack = _webcamStream.getVideoTracks()[0];
          if (videoTrack) pc.addTrack(videoTrack, _webcamStream);
        }

        dataChannel = pc.createDataChannel("parameters", { ordered: true });
        dataChannel.onopen = () => {
          statusEl.textContent = "";
          infoEl.textContent = connectionLabel();
          if (Object.keys(lastKnownParams).length) {
            dataChannel.send(JSON.stringify(lastKnownParams));
          }
        };

        dataChannel.onmessage = (event) => {
          const data = JSON.parse(event.data);
          if (data.type === "stream_stopped" && gen === _startGen) {
            statusEl.textContent = "stream stopped";
            pc.close();
            _activePc = null;
            setTimeout(start, 3000);
          }
        };

        // Receive transceiver for Scope's output video
        pc.addTransceiver("video");
        pc.ontrack = (event) => {
          if (event.streams?.[0]) {
            videoEl.srcObject = event.streams[0];
            startFPS();
          }
        };

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        if (gen !== _startGen) { pc.close(); return; }

        let sessionId = null;
        const queued = [];

        pc.onicecandidate = async (event) => {
          if (!event.candidate) return;
          if (sessionId) {
            await fetch(`${API_BASE}/api/v1/webrtc/offer/${sessionId}`, {
              method: "PATCH",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ candidates: [{
                candidate: event.candidate.candidate,
                sdpMid: event.candidate.sdpMid,
                sdpMLineIndex: event.candidate.sdpMLineIndex
              }]})
            });
          } else {
            queued.push(event.candidate);
          }
        };

        const sdpRes = await fetch(`${API_BASE}/api/v1/webrtc/offer`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            sdp: pc.localDescription.sdp,
            type: pc.localDescription.type,
            initialParameters: lastKnownParams
          })
        });
        if (gen !== _startGen) { pc.close(); return; }

        const answer = await sdpRes.json();
        sessionId = answer.sessionId;
        await pc.setRemoteDescription({ type: answer.type, sdp: answer.sdp });

        if (queued.length) {
          await fetch(`${API_BASE}/api/v1/webrtc/offer/${sessionId}`, {
            method: "PATCH",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ candidates: queued.map(c => ({
              candidate: c.candidate, sdpMid: c.sdpMid, sdpMLineIndex: c.sdpMLineIndex
            }))})
          });
        }

        pc.onconnectionstatechange = () => {
          if (pc.connectionState === "failed" || pc.connectionState === "disconnected") {
            if (gen === _startGen) {
              statusEl.textContent = "reconnecting...";
              pc.close();
              _activePc = null;
              setTimeout(start, 2000);
            }
          }
        };

      } catch (e) {
        if (gen === _startGen) {
          statusEl.textContent = `error: ${e.message}`;
          setTimeout(start, 3000);
        }
      }
    }

    // Webcam toggle.
    // Closing the PC and calling start() increments _startGen, which causes
    // any currently-running start() to abort when it next checks gen !== _startGen.
    webcamCtrl.addEventListener("click", async () => {
      if (_webcamStream) {
        _webcamStream.getTracks().forEach(t => t.stop());
        _webcamStream = null;
        webcamCtrl.textContent = "CAM";
        webcamCtrl.className = "";
        if (_activePc) { _activePc.close(); _activePc = null; }
        start();
      } else {
        try {
          webcamCtrl.textContent = "CAM...";
          _webcamStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
          webcamCtrl.textContent = "CAM ●";
          webcamCtrl.className = "active";
          if (_activePc) { _activePc.close(); _activePc = null; }
          start();
        } catch (e) {
          webcamCtrl.textContent = "CAM ✕";
          webcamCtrl.className = "error";
          setTimeout(() => { webcamCtrl.textContent = "CAM"; webcamCtrl.className = ""; }, 3000);
          _webcamStream = null;
        }
      }
    });

    start();
  </script>
</body>
</html>
